{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "#### Extracting linguistic features using ```spaCy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695/1459457600.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# import modules \n",
    "import spacy\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "# loading the spacy model\n",
    "# define pipeline\n",
    "nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Preprocessing``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jg hedder ida   ... --'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the dataframe it seems the text has some spaces enoced as \"\\n\". We want to replace these with spaces. \n",
    "# we also want to get rid of the doc.id and title between the brackets \n",
    "\n",
    "# make function to clean the text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function removes extra white spaces \"\\n\" and characters between < and >, and trailing whitespaces (.strip). \n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r'<.*?>|\\s+', ' ', text).strip()\n",
    "\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get relative frequency of ```Nouns, Verbs, Adjective, and Adverbs``` per 10,000 words\n",
    "### And get total number of *unique* PER, LOC, ORGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one long function \n",
    "\n",
    "def processing(path):    \n",
    "    # open it and read it \n",
    "    with open(path, encoding=\"latin-1\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    #doc = clean_text(doc)\n",
    "\n",
    "    # see some attributes \n",
    "    counts_per_pos = {\"NOUN\": 0, \"ADV\": 0, \"ADJ\": 0, \"VERB\": 0} # make dictionary \n",
    "\n",
    "    for token in doc: \n",
    "        if token.pos_ in counts_per_pos: # only take NOUN, ADV, ADj and VERB\n",
    "                # get text and label \n",
    "            counts_per_pos[token.pos_] += 1\n",
    "\n",
    "\n",
    "    counts_per_label = {\"PERSON\": 0, \"LOC\": 0, \"ORG\": 0}\n",
    "\n",
    "    # docs is a list of spaCy Doc objects\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ in counts_per_label:\n",
    "            # Increment the count for each label\n",
    "            counts_per_label[entity.label_] += 1\n",
    "\n",
    "    \n",
    "    data = counts_per_label | counts_per_pos # merge the two dictionaries \n",
    "        \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "#make relative...; \n",
    "#  counts = df[\"pos\"].value_counts()\n",
    "#                relative_freqs_per_10000 = (counts / len(df)) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over each text file in the folder called ```in```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/CDS-language/CDS-language/Assignments/Assignment1_lang/src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current working directory \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "file_path = os.path.join(\n",
    "    \"..\", \n",
    "    \"in\",\n",
    "    \"USEcorpus\")\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"..\", \n",
    "    \"out\")\n",
    "\n",
    "dirs = sorted(os.listdir(file_path))\n",
    "\n",
    "\n",
    "# loop through the paths \n",
    "for directory in dirs: \n",
    "    subfolder = os.path.join(file_path, directory) # path.join instead of \"datapath + \"/\" + directory\"\n",
    "    filenames = sorted(os.listdir(subfolder))\n",
    "\n",
    "    corpus_texts = [] # make empty list to append the texts \n",
    "\n",
    "    for text_file in filenames:\n",
    "        path = os.path.join(subfolder,text_file)\n",
    "        data = processing(path)\n",
    "        \n",
    "        corpus_texts.append({'File': text_file, 'Folder': directory, **data}) # use dictionary, so it's easier to convert to df with the folder and file name\n",
    "\n",
    "\n",
    "        # Convert the list of dictionaries to a pandas DataFrame\n",
    "    corpus_df = pd.DataFrame(corpus_texts)\n",
    "    df.to_csv(os.path.join(output_path, f\"{directory}_spacy.csv\"), index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Folder</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0140.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>386</td>\n",
       "      <td>99</td>\n",
       "      <td>116</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0165.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>429</td>\n",
       "      <td>70</td>\n",
       "      <td>143</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0200.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>234</td>\n",
       "      <td>101</td>\n",
       "      <td>129</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0219.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>208</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0238.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0501.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0502.c1.txt</td>\n",
       "      <td>c1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>207</td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          File Folder  PERSON  LOC  ORG  NOUN  ADV  ADJ  VERB\n",
       "0  0140.c1.txt     c1      78    0    8   386   99  116   229\n",
       "1  0165.c1.txt     c1      52    0    6   429   70  143   201\n",
       "2  0200.c1.txt     c1      79    0   11   234  101  129   203\n",
       "3  0219.c1.txt     c1      72    0    6   208   73   85   147\n",
       "4  0238.c1.txt     c1      62    0    4   140   37   51   149\n",
       "5  0501.c1.txt     c1      54    0    6   179   62   67   149\n",
       "6  0502.c1.txt     c1      40    0   26   207   64   68   191"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Preprocessing``` functions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:\n",
    "| Filename  | RelFreq NOUN | RelFreq VERB | RelFreq ADJ | RelFreq ADV | Unique PER | Unique LOC | Unique ORG |\n",
    "|-----------|--------------|--------------|-------------|-------------|------------|------------|------------|\n",
    "| file1.txt | ---          | ---          | ---         | ---         | ---        | ---        | ---        |\n",
    "| file2.txt | ---          | ---          | ---         | ---         | ---        | ---        | ---        |\n",
    "| etc       | ---          | ---          | ---         | ---         | ---        | ---        | ---        |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
